{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QFVKiU4m4Uu"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "import sklearn \n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset\n",
        "\n",
        "dftrain = pd.read_csv(\n",
        "    'https://storage.googleapis.com/tf-datasets/titanic/train.csv'\n",
        "    ) #trainingdata\n",
        "\n",
        "dfeval = pd.read_csv(\n",
        "    'https://storage.googleapis.com/tf-datasets/titanic/eval.csv'\n",
        ") # testing data\n",
        "\n",
        "# We separate the data to see how the model works on new data. \n",
        "# Can't just memorize answers then"
      ],
      "metadata": {
        "id": "n5mSqNcbnGu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These are our outputs, so we are going to keep this \n",
        "# Column separate \n",
        "y_train = dftrain.pop('survived')\n",
        "y_eval = dfeval.pop('survived')"
      ],
      "metadata": {
        "id": "2iq-u7UTnLDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Training and Testing Datasets**\n",
        "\n",
        "Above we loaded two datasets, one for training and one for testing. \n",
        "\n",
        "* We train the data on usually significantly more data than we do to test \n",
        "* Goal is to make predictions on NEW data, so we should't test it on old data "
      ],
      "metadata": {
        "id": "FZRHt5FunNK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorical vs Numeric Data and Feature Columns**\n",
        "\n",
        "* *Categorical data* - Data that has categories, and not numeric. Example: Male vs Female\n",
        "  * We have to transfer this to numeric data somehow. So we can represent female by 0 and male by 1\n",
        "* *Numeric data* - integer based data \n",
        "* **feature columns** - what we feed to our model to make prediction"
      ],
      "metadata": {
        "id": "SUiqyNVinhQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Types of data\n",
        "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
        "                       'deck', 'embark_town', 'alone']\n",
        "NUMERIC_COLUMNS = ['age', 'fare']\n",
        "\n",
        "feature_columns = []\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocab = dftrain[feature_name].unique() \n",
        "  # ^ this is getting all unique values from feature columns\n",
        "  feature_columns.append(\n",
        "      tf.feature_column.categorical_column_with_vocabulary_list(feature_name, \n",
        "                                                                vocab))\n",
        "  # ^ creates a column with the feature_name and different vocab associated with it \n",
        "  \n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(\n",
        "      feature_name, dtype=tf.float32))\n",
        "  \n",
        "feature_columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4acJ-R9ZoQHv",
        "outputId": "5bee2571-cf5d-48ff-db1f-06c169d0065a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
              " VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0),\n",
              " VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0),\n",
              " VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
              " VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
              " VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
              " VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
              " NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Training Process**\n",
        "\n",
        "Sometimes we have a lot of data, and we don't have enough RAM to process it. We load the data in batches in order to overcome this. \n",
        "\n",
        "We give 32 entries at once (faster than 1 at a time). We feed batches multiple times according to number of **epochs**\n",
        "\n",
        "An **epoch** is feeding the data in a different order to the model. This makes the model 'see' the data in a different way\n",
        "  * This can cause the model to overfit, so to prevent this we make sure we start on a lower amount of epochs and build up to more\n",
        "\n",
        "To now feed our data, with need to create an **input function**"
      ],
      "metadata": {
        "id": "WGwxRow9qmXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Input Functions\n",
        "\n",
        "This is the way we define how our data is broken into epochs to feed to our data. Likely never have to write one from scratch. "
      ],
      "metadata": {
        "id": "jYVcY481rZEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_input_fn(data_df, label_df, \n",
        "                  num_epochs=10, shuffle=True, batch_size=32):\n",
        "  # data_df = data frame being base\n",
        "  # label_df = labels in df form\n",
        "  # num_epochs = number of epochs\n",
        "  # shuffle = Wether we will shuffle or not \n",
        "  # batch size = size of the batch \n",
        "  def input_function():\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
        "    # ^ create a dict representation of df and pass label df to create an object\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000) # shuffles data set \n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    return ds\n",
        "  return input_function # returns function object \n",
        "\n",
        "train_input_fn = make_input_fn(dftrain, y_train)\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)"
      ],
      "metadata": {
        "id": "E-iMMCo3r3mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Creating the Model**\n",
        "\n"
      ],
      "metadata": {
        "id": "0tJLC863tghR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the model\n",
        "linear_est = tf.estimator.LinearClassifier(\n",
        "    feature_columns=feature_columns) \n",
        "# this creates the linear regression model from tf lib\n",
        "\n",
        "# training model\n",
        "linear_est.train(train_input_fn)\n",
        "result = linear_est.evaluate(eval_input_fn)\n",
        "\n",
        "clear_output() # clear the console\n",
        "\n",
        "# notice how if we run it multiple times, our accuracy changes\n",
        "# this is cuz our data changes with every shuffle which leds to new results \n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZreoqzdtmuu",
        "outputId": "a18518d8-ea45-4c8c-eef7-52e416c03a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.77272725,\n",
              " 'accuracy_baseline': 0.625,\n",
              " 'auc': 0.833517,\n",
              " 'auc_precision_recall': 0.792598,\n",
              " 'average_loss': 0.48287693,\n",
              " 'global_step': 200,\n",
              " 'label/mean': 0.375,\n",
              " 'loss': 0.47366652,\n",
              " 'precision': 0.71910113,\n",
              " 'prediction/mean': 0.337282,\n",
              " 'recall': 0.64646465}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow is much better at working with large data sets instead of just one point. In this case, a set of people vs one passenger "
      ],
      "metadata": {
        "id": "rDn_gyDnuyzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's predict one person\n",
        "result = list(linear_est.predict(eval_input_fn)) # loops through\n",
        "clear_output()\n",
        "result[0] # list of each prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXe6S9m5u7ed",
        "outputId": "8331cd4a-31fe-4e04-bc07-a5c060b154da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'all_class_ids': array([0, 1], dtype=int32),\n",
              " 'all_classes': array([b'0', b'1'], dtype=object),\n",
              " 'class_ids': array([0]),\n",
              " 'classes': array([b'0'], dtype=object),\n",
              " 'logistic': array([0.06220323], dtype=float32),\n",
              " 'logits': array([-2.713126], dtype=float32),\n",
              " 'probabilities': array([0.9377968 , 0.06220326], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look closer at `'probabilities': array([0.9377968 , 0.06220326], dtype=float32)}`. This is saying there's a 93.8% change they don't survivce, and 6.2% change they do. If there were more classifications, the model would break it up more.  \n",
        "\n",
        "So, if we wanted to get the specific chance that they survive, we would just do \n",
        "\n",
        "`result[0]['probabilities'][1]`"
      ],
      "metadata": {
        "id": "UVoDnlgqvcLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see the person and see if it makes sense\n",
        "\n",
        "print(dfeval.loc[0])\n",
        "print(y_eval.loc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWYBAf3mwPGI",
        "outputId": "8571c7d6-2318-4c5c-8358-7ec0d573120a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sex                          male\n",
            "age                          35.0\n",
            "n_siblings_spouses              0\n",
            "parch                           0\n",
            "fare                         8.05\n",
            "class                       Third\n",
            "deck                      unknown\n",
            "embark_town           Southampton\n",
            "alone                           y\n",
            "Name: 0, dtype: object\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see this person was male, single, no sibling, third class, and alone, so they had a low % chance of surviving. This makes sense and they didn't survive.\n",
        "\n",
        "For others, it may not be ass accurate "
      ],
      "metadata": {
        "id": "ZSpe0RaUwYSM"
      }
    }
  ]
}